{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45df68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rs_students/miniconda3/envs/pitch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "from transformers import AutoTokenizer\n",
    "import Levenshtein\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0319a1",
   "metadata": {},
   "source": [
    "## Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b01a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"Datasets/filtered_sanskritdoc.txt\"\n",
    "train_file = \"Datasets/train.txt\"\n",
    "val_file = \"Datasets/val.txt\"\n",
    "test_file = \"Datasets/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e334b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "MODEL_NAME = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "OUTPUT_DIR = \"outputs_pitch_restore\"\n",
    "MBART_LANG = \"hi_IN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d8897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEDIC_ACCENTS_EXPLICIT = ['\\u0951', '\\u0952', '\\u0953', '\\u0954', '\\u1CDA']\n",
    "COMBINING_MARK_RANGES = [\n",
    "    (0x0951, 0x0954),\n",
    "    (0x1CD0, 0x1CFF),\n",
    "    # (0xA8E0, 0xA8FF),  # enable if needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf1eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f6bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "train_sentences = load_sentences(train_file)\n",
    "val_sentences = load_sentences(val_file)\n",
    "test_sentences = load_sentences(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e09e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23004\n",
      "4929\n",
      "4931\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences))\n",
    "print(len(val_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2298dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def strip_combining_ranges(text, ranges):\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "    res = []\n",
    "    for ch in text:\n",
    "        code = ord(ch)\n",
    "        if any(lo <= code <= hi for lo, hi in ranges):\n",
    "            continue\n",
    "        res.append(ch)\n",
    "    out = \"\".join(res)\n",
    "    for mark in VEDIC_ACCENTS_EXPLICIT:\n",
    "        out = out.replace(mark, \"\")\n",
    "    return \" \".join(out.split())\n",
    "\n",
    "def make_dataframe(sentences):\n",
    "    return pd.DataFrame({\n",
    "        \"input_text\": [strip_combining_ranges(s, COMBINING_MARK_RANGES) for s in sentences],\n",
    "        \"target_text\": [unicodedata.normalize(\"NFC\", s) for s in sentences]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a79be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = make_dataframe(train_sentences)\n",
    "df_val = make_dataframe(val_sentences)\n",
    "df_test = make_dataframe(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58aab9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23004, 2)\n",
      "(4929, 2)\n",
      "(4931, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f7a545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>कीलालपे सोमपृष्ठाय वेधसे हृदा मतिं जनये चारुमग...</td>\n",
       "      <td>की॒ला॒ल॒पे सोम॑पृष्ठाय वे॒धसे॑ हृ॒दा म॒तिं ज॑न...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>नमो ह्रदय्याय च नमः । निवेष्प्याय च नमः ।</td>\n",
       "      <td>नमो᳚ ह्रद॒य्या॑य च॒ नमः॑ । नि॒वे॒ष्प्या॑य च॒ न...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>इन्द्रं मित्रं वरुणमग्निमाहुरथो दिव्यः स सुपर्...</td>\n",
       "      <td>इन्द्रं॑ मि॒त्रं वरु॑णम॒ग्निमा॑हु॒रथो॑ दि॒व्यः...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>क्रतुर्भवत्युक्थ्यः ॥ १.०१७.०५</td>\n",
       "      <td>क्रतु॑र्भवत्यु॒क्थ्यः॑ ॥ १.०१७.०५</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ये ते त्रिरहन्सवितः सवासो दिवेदिवे सौभगमासुवन्...</td>\n",
       "      <td>ये ते॒ त्रिरह॑न्सवितः स॒वासो॑ दि॒वेदि॑वे॒ सौभ॑...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  कीलालपे सोमपृष्ठाय वेधसे हृदा मतिं जनये चारुमग...   \n",
       "1          नमो ह्रदय्याय च नमः । निवेष्प्याय च नमः ।   \n",
       "2  इन्द्रं मित्रं वरुणमग्निमाहुरथो दिव्यः स सुपर्...   \n",
       "3                     क्रतुर्भवत्युक्थ्यः ॥ १.०१७.०५   \n",
       "4  ये ते त्रिरहन्सवितः सवासो दिवेदिवे सौभगमासुवन्...   \n",
       "\n",
       "                                         target_text  \n",
       "0  की॒ला॒ल॒पे सोम॑पृष्ठाय वे॒धसे॑ हृ॒दा म॒तिं ज॑न...  \n",
       "1  नमो᳚ ह्रद॒य्या॑य च॒ नमः॑ । नि॒वे॒ष्प्या॑य च॒ न...  \n",
       "2  इन्द्रं॑ मि॒त्रं वरु॑णम॒ग्निमा॑हु॒रथो॑ दि॒व्यः...  \n",
       "3                  क्रतु॑र्भवत्यु॒क्थ्यः॑ ॥ १.०१७.०५  \n",
       "4  ये ते॒ त्रिरह॑न्सवितः स॒वासो॑ दि॒वेदि॑वे॒ सौभ॑...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a3f390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identical lines (plain==pitched): 0\n"
     ]
    }
   ],
   "source": [
    "n_identical = (df_val[\"input_text\"] == df_val[\"target_text\"]).sum()\n",
    "print(f\"\\nIdentical lines (plain==pitched): {n_identical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491a7c7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edffadc7",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb3118ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rs_students/miniconda3/envs/pitch/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added accent tokens to tokenizer. New vocab size: 250055\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_tokens(VEDIC_ACCENTS_EXPLICIT, special_tokens=False)              # one token added\n",
    "print(\"Added accent tokens to tokenizer. New vocab size:\", len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8801b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(tokenizer, \"lang_code_to_id\") and MBART_LANG in tokenizer.lang_code_to_id:\n",
    "    tokenizer.src_lang = MBART_LANG\n",
    "    tokenizer.tgt_lang = MBART_LANG\n",
    "else:\n",
    "    # Fallback: still proceed, but warn once.\n",
    "    print(f\"[WARN] MBART language code '{MBART_LANG}' not found in tokenizer.lang_code_to_id. \"\n",
    "          f\"Proceeding without forced language BOS; decoding quality may degrade.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90791cb2",
   "metadata": {},
   "source": [
    "### Model arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87f24dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = Seq2SeqArgs()\n",
    "model_args.num_train_epochs = 1\n",
    "model_args.train_batch_size = 8\n",
    "model_args.eval_batch_size = 8\n",
    "model_args.max_sequence_length = 256\n",
    "model_args.max_length = 256\n",
    "model_args.evaluate_generated_text = True\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.use_multiprocessing = False\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.output_dir = OUTPUT_DIR\n",
    "model_args.best_model_dir = os.path.join(OUTPUT_DIR, \"best_model\")\n",
    "model_args.fp16 = torch.cuda.is_available()\n",
    "model_args.save_eval_checkpoints = True\n",
    "model_args.save_model_every_epoch = False\n",
    "model_args.evaluate_during_training_steps = 1000\n",
    "model_args.logging_steps = 200\n",
    "model_args.save_steps = 1000\n",
    "model_args.learning_rate = 5e-5\n",
    "model_args.gradient_accumulation_steps = 4\n",
    "model_args.use_multiprocessing_for_evaluation = False\n",
    "model_args.num_beams = 5\n",
    "model_args.length_penalty = 1.0\n",
    "model_args.early_stopping = True                 \n",
    "model_args.early_stopping_metric = \"eval_loss\"  \n",
    "model_args.early_stopping_metric_minimize = True\n",
    "model_args.early_stopping_patience = 3\n",
    "model_args.max_grad_norm = 1.0                   \n",
    "model_args.reprocess_input_data = True          \n",
    "model_args.save_best_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "434b312f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \n",
      "The class this function is called from is 'MBartTokenizer'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \n",
      "The class this function is called from is 'MBartTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "model = Seq2SeqModel(\n",
    "    encoder_decoder_type = \"mbart\",\n",
    "    encoder_decoder_name = MODEL_NAME,\n",
    "    tokenizer = tokenizer,\n",
    "    args = model_args,\n",
    "    use_cuda = use_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16a91fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(250055, 1024)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95706578",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(tokenizer, \"lang_code_to_id\") and MBART_LANG in tokenizer.lang_code_to_id:\n",
    "    forced_id = tokenizer.lang_code_to_id[MBART_LANG]\n",
    "    model.model.config.forced_bos_token_id = forced_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b8bb2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4360f00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training with 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23004 [00:00<?, ?it/s]/home/rs_students/miniconda3/envs/pitch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3745: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "/home/rs_students/miniconda3/envs/pitch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "100%|██████████| 23004/23004 [00:10<00:00, 2117.34it/s]\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]/home/rs_students/miniconda3/envs/pitch/lib/python3.10/site-packages/simpletransformers/seq2seq/seq2seq_model.py:727: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 1:   0%|          | 0/1 [00:00<?, ?it/s]/home/rs_students/miniconda3/envs/pitch/lib/python3.10/site-packages/simpletransformers/seq2seq/seq2seq_model.py:751: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Epochs 1/1. Running Loss:    0.2560: 100%|██████████| 2876/2876 [08:08<00:00,  5.89it/s]\n",
      "100%|██████████| 4929/4929 [00:02<00:00, 2176.47it/s]\n",
      "/home/rs_students/miniconda3/envs/pitch/lib/python3.10/site-packages/simpletransformers/seq2seq/seq2seq_model.py:1211: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "/home/rs_students/miniconda3/envs/pitch/lib/python3.10/site-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Generating outputs: 100%|██████████| 617/617 [07:06<00:00,  1.45it/s]\n",
      "Epoch 1 of 1: 100%|██████████| 1/1 [16:28<00:00, 988.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(719,\n",
       " {'global_step': [719],\n",
       "  'eval_loss': [0.31622945199716035],\n",
       "  'train_loss': [0.2559961676597595]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\nStarting training with {model_args.num_train_epochs} epochs\")\n",
    "model.train_model(\n",
    "    train_data=df_train,\n",
    "    eval_data=df_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dda46b",
   "metadata": {},
   "source": [
    "#### For 1 epoch training \n",
    "\n",
    "    (719,\n",
    "\n",
    "        {'global_step': [719],\n",
    "\n",
    "        'eval_loss': [0.31651537043059086],\n",
    "    \n",
    "        'train_loss': [0.36946552991867065]})\n",
    "\n",
    "    Simple eval results {'eval_loss': 0.30853030095224054}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "657943b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4931 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4931/4931 [00:02<00:00, 2098.33it/s]\n",
      "Running Evaluation: 100%|██████████| 617/617 [00:29<00:00, 21.02it/s]\n",
      "Generating outputs: 100%|██████████| 617/617 [07:11<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple eval results {'eval_loss': 0.30947082855616437}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_results = model.eval_model(df_test, verbose=True)\n",
    "print(\"Simple eval results\", raw_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9557169",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e361239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 9) Custom metrics\n",
    "# ------------------------\n",
    "# def char_accuracy(pred, ref):\n",
    "#     L = max(len(pred), len(ref))\n",
    "#     pred_p, ref_p = pred.ljust(L), ref.ljust(L)\n",
    "#     return sum(1 for a, b in zip(pred_p, ref_p) if a == b) / L\n",
    "\n",
    "# def word_accuracy(pred, ref):\n",
    "#     p_tokens, r_tokens = pred.split(), ref.split()\n",
    "#     minlen = min(len(p_tokens), len(r_tokens))\n",
    "#     matches = sum(1 for i in range(minlen) if p_tokens[i] == r_tokens[i])\n",
    "#     return matches / max(len(r_tokens), 1)\n",
    "\n",
    "def exact_match(pred, ref):\n",
    "    return int(pred.strip() == ref.strip())\n",
    "\n",
    "def pitch_positions(s, pitch_tokens=None):\n",
    "    if pitch_tokens is None:\n",
    "        # Define as any char in the configured ranges or explicit list\n",
    "        pts = set(VEDIC_ACCENTS_EXPLICIT)\n",
    "        def is_pitch_char(ch):\n",
    "            c = ord(ch)\n",
    "            return (ch in pts) or any(lo <= c <= hi for lo, hi in COMBINING_MARK_RANGES)\n",
    "    else:\n",
    "        pts = set(pitch_tokens)\n",
    "        def is_pitch_char(ch):\n",
    "            return ch in pts\n",
    "    return {(i, c) for i, c in enumerate(s) if is_pitch_char(c)}\n",
    "\n",
    "# def pitch_accuracy(pred, ref, pitch_tokens=None):\n",
    "#     pred_pos = pitch_positions(pred, pitch_tokens)\n",
    "#     ref_pos  = pitch_positions(ref, pitch_tokens)\n",
    "#     matches = len(pred_pos & ref_pos)\n",
    "#     return matches / max(len(ref_pos), 1)\n",
    "\n",
    "def pitch_f1(pred, ref, pitch_tokens=None):\n",
    "    pred_set = pitch_positions(pred, pitch_tokens)\n",
    "    ref_set  = pitch_positions(ref, pitch_tokens)\n",
    "    tp = len(pred_set & ref_set)\n",
    "    fp = len(pred_set - ref_set)\n",
    "    fn = len(ref_set - pred_set)\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall    = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1        = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    return f1\n",
    "\n",
    "def extract_pitch_string(s):\n",
    "    \"\"\"Return a string containing only the pitch marks from s.\"\"\"\n",
    "    return \"\".join(\n",
    "        ch for i, ch in enumerate(s)\n",
    "        if (ch in VEDIC_ACCENTS_EXPLICIT) or any(lo <= ord(ch) <= hi for lo, hi in COMBINING_MARK_RANGES)\n",
    "    )\n",
    "\n",
    "def pitch_edit_distance(pred, ref):\n",
    "    \"\"\"Compute raw and normalized edit distance for pitch accents only.\"\"\"\n",
    "    pred_pitch = extract_pitch_string(pred)\n",
    "    ref_pitch  = extract_pitch_string(ref)\n",
    "    dist = Levenshtein.distance(pred_pitch, ref_pitch)\n",
    "    norm = dist / max(len(ref_pitch), 1)\n",
    "    return dist, norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796571d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics: {'exact_match_rate': 0.08720340701683228, 'pitch_f1_mean': 0.33154141694368316, 'avg_pitch_edit_distance_norm': 0.34143245442304815, 'corpus_BLEU': 49.95357356445782}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# 10) Predictions & Metrics\n",
    "# ------------------------\n",
    "\n",
    "\n",
    "\n",
    "batch_inputs = df_test[\"input_text\"].tolist()\n",
    "\n",
    "# Keep decoding params explicit\n",
    "model.args.max_length = 256\n",
    "model.args.num_beams = 5\n",
    "\n",
    "preds = model.predict(batch_inputs)\n",
    "\n",
    "exacts = []\n",
    "pitch_f1s = []\n",
    "pitch_edit_raw, pitch_edit_norm = [], []\n",
    "\n",
    "refs = df_test[\"target_text\"].tolist()\n",
    "hyps = preds\n",
    "\n",
    "for pred, ref in zip(hyps, refs):\n",
    "    exacts.append(exact_match(pred, ref))\n",
    "    pitch_f1s.append(pitch_f1(pred, ref))    \n",
    "    d_raw, d_norm = pitch_edit_distance(pred, ref)\n",
    "    pitch_edit_raw.append(d_raw)\n",
    "    pitch_edit_norm.append(d_norm)\n",
    "\n",
    "\n",
    "bleu_score = sacrebleu.corpus_bleu(hyps, [refs]).score if hyps else 0.0\n",
    "\n",
    "print(\"\\nEvaluation Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Exact Match Rate:             {float(np.mean(exacts)) * 100:.2f}%\")\n",
    "print(f\"Pitch F1 Score (mean):        {float(np.mean(pitch_f1s)) * 100:.2f}%\")\n",
    "print(f\"Pitch Edit Distance (norm):   {float(np.mean(pitch_edit_norm)) * 100:.2f}%\")\n",
    "print(f\"Corpus BLEU:                  {float(bleu_score):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d1596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results\n",
      "==================================================\n",
      "Exact Match Rate:             8.72%\n",
      "Pitch F1 Score (mean):        33.15%\n",
      "Pitch Edit Distance (norm):   34.14%\n",
      "Corpus BLEU:                  49.95\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89715342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results\n",
      "==================================================\n",
      "The exact matching sentences are 8.72% (model output fully correct without any error).\n",
      "The average Pitch F1 score is 33.15%, which balances how many pitch accents were predicted correctly and how many were missed/over-predicted.\n",
      "The average normalized pitch edit distance is 34.14%, meaning on average this percentage of pitch accents would need correction.\n",
      "The corpus BLEU score is 49.95, showing overall sequence similarity with the reference text.\n"
     ]
    }
   ],
   "source": [
    "exact_match_rate = float(np.mean(exacts)) * 100\n",
    "pitch_f1_mean = float(np.mean(pitch_f1s)) * 100\n",
    "pitch_edit_norm = float(np.mean(pitch_edit_norm)) * 100\n",
    "bleu = float(bleu_score)\n",
    "\n",
    "print(\"\\nEvaluation Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"The exact matching sentences are {exact_match_rate:.2f}% \"\n",
    "      f\"(model output fully correct without any error).\")\n",
    "\n",
    "print(f\"The average Pitch F1 score is {pitch_f1_mean:.2f}%, \"\n",
    "      f\"which balances how many pitch accents were predicted correctly \"\n",
    "      f\"and how many were missed/over-predicted.\")\n",
    "\n",
    "print(f\"The average normalized pitch edit distance is {pitch_edit_norm:.2f}%, \"\n",
    "      f\"meaning on average this percentage of pitch accents would need correction.\")\n",
    "\n",
    "print(f\"The corpus BLEU score is {bleu:.2f}, \"\n",
    "      f\"showing overall sequence similarity with the reference text.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be98e3",
   "metadata": {},
   "source": [
    "1 epoch Detailed metrics: \n",
    "\n",
    "'char_accuracy_mean': 0.4939109582960301, \n",
    "                    \n",
    "'word_accuracy_mean': 0.5942787050558115, \n",
    "                    \n",
    "'exact_match_rate': 0.08720340701683228, \n",
    "                    \n",
    "'avg_levenshtein': 5.867572500506997, \n",
    "                    \n",
    "'pitch_accuracy_mean': 0.3327242539902244, \n",
    "                    \n",
    "'pitch_f1_mean': 0.33154141694368316, \n",
    "                    \n",
    "'corpus_BLEU': 49.95357356445782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qualitative examples:\n",
      "---\n",
      "INPUT : कीलालपे सोमपृष्ठाय वेधसे हृदा मतिं जनये चारुमग्नये ॥ १०.०९१.१४\n",
      "TARGET: की॒ला॒ल॒पे सोम॑पृष्ठाय वे॒धसे॑ हृ॒दा म॒तिं ज॑नये॒ चारु॑म॒ग्नये॑ ॥ १०.०९१.१४\n",
      "PRED  : की॒ला॒ल॒पे सोम॑पृष्ठाय वे॒धसे॑ हृ॒दा म॒तिं जन॑ये॒ चारु॒मग्न॑ये ॥ १०.०९१.१४\n",
      "\n",
      "---\n",
      "INPUT : नमो ह्रदय्याय च नमः । निवेष्प्याय च नमः ।\n",
      "TARGET: नमो᳚ ह्रद॒य्या॑य च॒ नमः॑ । नि॒वे॒ष्प्या॑य च॒ नमः॑ ।\n",
      "PRED  : नमो॑ ह्रदय्या॒य च॒ नमः॑ । निवे॒ष्प्या॑य च॒ नमः॑ ।\n",
      "\n",
      "---\n",
      "INPUT : इन्द्रं मित्रं वरुणमग्निमाहुरथो दिव्यः स सुपर्णो गरुत्मान् ।\n",
      "TARGET: इन्द्रं॑ मि॒त्रं वरु॑णम॒ग्निमा॑हु॒रथो॑ दि॒व्यः स सु॑प॒र्णो ग॒रुत्मा॑न् ।\n",
      "PRED  : इन्द्रं॑ मि॒त्रं वरु॑णम॒ग्निमा॑हुरथो दि॒व्यः स सु॒पर्णो॑ गरु॒त्मान् ।\n",
      "\n",
      "---\n",
      "INPUT : क्रतुर्भवत्युक्थ्यः ॥ १.०१७.०५\n",
      "TARGET: क्रतु॑र्भवत्यु॒क्थ्यः॑ ॥ १.०१७.०५\n",
      "PRED  : क्रतु॒र्भव॒त्युक्थ्यः॑ ॥ १.०१७.०५\n",
      "\n",
      "---\n",
      "INPUT : ये ते त्रिरहन्सवितः सवासो दिवेदिवे सौभगमासुवन्ति ।\n",
      "TARGET: ये ते॒ त्रिरह॑न्सवितः स॒वासो॑ दि॒वेदि॑वे॒ सौभ॑गमासु॒वन्ति॑ ।\n",
      "PRED  : ये ते॑ त्रि॒रहन्स॒वितः॑ सवा॒सो दि॒वेदि॑वे सौभग॒मासु॑वन्ति ।\n",
      "\n",
      "---\n",
      "INPUT : मंहिष्ठं सिञ्च इन्दुभिः ॥ १.०३०.०१\n",
      "TARGET: मंहि॑ष्ठं सिञ्च॒ इन्दु॑भिः ॥ १.०३०.०१\n",
      "PRED  : मंहि॑ष्ठं सिञ्च॒ इन्दु॑भिः ॥ १.०३०.०१\n",
      "\n",
      "---\n",
      "INPUT : गिरो वाश्रास ईरते ॥ ८.०४४.२५\n",
      "TARGET: गिरो॑ वा॒श्रास॑ ईरते ॥ ८.०४४.२५\n",
      "PRED  : गि॒रो वा॒श्रास॑ ईरते ॥ ८.०४४.२५\n",
      "\n",
      "---\n",
      "INPUT : इन्द्रावरुणा युवमध्वराय नो विशे जनाय महि शर्म यच्छतम् ।\n",
      "TARGET: इन्द्रा॑वरुणा यु॒वम॑ध्व॒राय॑ नो वि॒शे जना॑य॒ महि॒ शर्म॑ यच्छतम् ।\n",
      "PRED  : इन्द्रा॑वरुणा युव॒मध्व॑राय नो॒ विशे॒ जना॑य॒ महि॒ शर्म॑ यच्छतम् ।\n",
      "\n",
      "---\n",
      "INPUT : नाहं तं वेद य इति ब्रवीत्यदेवयून्समरणे जघन्वान् ।\n",
      "TARGET: नाहं तं वे॑द॒ य इति॒ ब्रवी॒त्यदे॑वयून्स॒मर॑णे जघ॒न्वान् ।\n",
      "PRED  : नाहं॒ तं वे॒द य इ॒ति ब्रवी॒त्यदे॒वयू॒न्सम॒रणे॒ जघ॑न्वान् ।\n",
      "\n",
      "---\n",
      "INPUT : यं सीमनु प्रवतेव द्रवन्तं विश्वः पूरुर्मदति हर्षमाणः ।\n",
      "TARGET: यं सी॒मनु॑ प्र॒वते॑व॒ द्रव॑न्तं॒ विश्वः॑ पू॒रुर्मद॑ति॒ हर्ष॑माणः ।\n",
      "PRED  : यं सी॒मनु॒ प्रव॑तेव॒ द्रव॑न्तं वि॒श्वः पू॒रुर्म॑दति हर्ष॒माणः॑ ।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQualitative examples:\")\n",
    "for i in range(min(10, len(batch_inputs))):\n",
    "    print(\"---\")\n",
    "    print(\"INPUT :\", batch_inputs[i])\n",
    "    print(\"TARGET:\", refs[i])\n",
    "    print(\"PRED  :\", hyps[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe07331",
   "metadata": {},
   "source": [
    "\n",
    "1. pitch_f1_mean\n",
    "This comes from precision and recall applied to pitch accent symbols.\n",
    "Precision = of all the accents the model predicted, how many were correct?\n",
    "Recall = of all the accents in the reference, how many did the model recover?\n",
    "F1 score = harmonic mean of precision and recall (balances the two).\n",
    "👉 Formula: 2*P*R/(P+R)\n",
    "\n",
    "\n",
    "2. avg_pitch_edit_distance_norm\n",
    "This uses edit distance but only on pitch marks.\n",
    "Edit distance = minimum number of edits (insert, delete, substitute) needed to transform prediction → reference.\n",
    "👉 Then we normalize it by the number of reference accents:\n",
    "\n",
    "char_accuracy → character-level correctness\n",
    "word_accuracy → word-level correctness\n",
    "exact_match → whole-sentence correctness\n",
    "pitch_accuracy → correctness of accent placement (recall-oriented)\n",
    "pitch_f1 → precision/recall balance for accents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c83c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pitch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
